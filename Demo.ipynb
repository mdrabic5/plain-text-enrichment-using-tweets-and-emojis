{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_TWEETS = \"ALL\"\n",
    "# NUMBER_OF_TWEETS = 100000\n",
    "\n",
    "MAX_WORDS_PER_TWEET = 30\n",
    "# DATA_LOCATION = \"./train/data/noise/\"\n",
    "DATA_LOCATION = \"./train/data/clean/\"\n",
    "# DATA_LOCATION = \"./train/data/words/\"\n",
    "RESULT_LOCATION = \"./result/\"\n",
    "TWEET_FILE_NAME = \"tweet_by_ID_28_4_2018__03_20_05\" + \"_\"\n",
    "\n",
    "if NUMBER_OF_TWEETS is not None:\n",
    "    TWEET_FILE_NAME += str(NUMBER_OF_TWEETS)\n",
    "else:\n",
    "    TWEET_FILE_NAME += \"ALL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets 473459\n"
     ]
    }
   ],
   "source": [
    "base_file_name = DATA_LOCATION + TWEET_FILE_NAME\n",
    "\n",
    "text_lines = []\n",
    "text_lines_split = []\n",
    "\n",
    "with open(base_file_name + \".text\", 'r', encoding=\"utf-8\") as out_text:\n",
    "    for line in out_text:\n",
    "        text_lines.append(line[:-1])\n",
    "        text_lines_split.append(line[:-1].split())\n",
    "        \n",
    "loc_lines = []\n",
    "with open(base_file_name + \".loclabels\", 'r') as loc_labels:\n",
    "    for line in loc_labels:\n",
    "        loc_line = []\n",
    "        for c in line[:-1]:\n",
    "            loc_line.append(int(c))\n",
    "        loc_lines.append(loc_line)\n",
    "\n",
    "loc_lines = np.asarray(loc_lines)\n",
    "\n",
    "emo_lines = []\n",
    "with open(base_file_name + \".emolabels\", 'r') as emo_labels:\n",
    "    for e_line, loc in zip(emo_labels, loc_lines):\n",
    "        emo_line = [0]*31\n",
    "        e_line2 = e_line.split()\n",
    "        \n",
    "        br = 0\n",
    "        for idx, val in enumerate(loc[:-1]):\n",
    "            if val==1:\n",
    "                emo_line[idx]=int(e_line2[br])+1\n",
    "                br += 1\n",
    "        emo_lines.append(emo_line)\n",
    "        \n",
    "emo_lines = np.asarray(emo_lines)\n",
    "\n",
    "print(f\"number of tweets {len(text_lines)}\")\n",
    "# print(f\"\\nexample of tweet texts:\")\n",
    "# for i in range(10):\n",
    "#     print(f\"{i}\\t{text_lines[i]}\")\n",
    "# print(f\"\\nexample of labels (emoji locations):\\n{loc_lines[:10]}\")\n",
    "# print(f\"\\nexample of labels (emoji type):\\n{emo_lines[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "EVALUATION_RESULTS_KEYS = ['Accuracy: ', 'Precision: ', 'Recall: ', 'F1: ', 'ratio of positive/negative predictions: ']\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "def vectorize_func(a, b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calc_scores(y_pred, y_test, multi_class):\n",
    "    result = []\n",
    "    \n",
    "    if multi_class:\n",
    "        result_temp = []\n",
    "    \n",
    "        for i in range(0, 21):\n",
    "            vfunc = np.vectorize(vectorize_func)\n",
    "            y_test_new = vfunc(y_test, i)\n",
    "            y_pred_new = vfunc(y_pred, i)\n",
    "            \n",
    "            result_temp2 = []\n",
    "            alfa=1\n",
    "            if i == 0:\n",
    "                alfa=1/5\n",
    "            \n",
    "            result_temp2.append(alfa*accuracy_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*precision_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*recall_score(y_pred_new, y_test_new))\n",
    "            result_temp2.append(alfa*f1_score(y_pred_new, y_test_new))\n",
    "            result_temp.append(result_temp2)\n",
    "    \n",
    "        result_avg = np.average(np.asarray(result_temp), axis=0)\n",
    "        result = result_avg[:]\n",
    "    else:\n",
    "        result.append(accuracy_score(y_pred, y_test))\n",
    "        result.append(precision_score(y_pred, y_test))\n",
    "        result.append(recall_score(y_pred, y_test))\n",
    "        result.append(f1_score(y_pred, y_test))\n",
    "        result.append(np.count_nonzero(y_pred) / y_pred.shape[0])\n",
    "    return result\n",
    "\n",
    "def print_scores(scores):\n",
    "    print(f\"Accuracy: {scores[0]}\")\n",
    "    print(f\"Precision: {scores[1]}\")\n",
    "    print(f\"Recall: {scores[2]}\")\n",
    "    print(f\"F1: {scores[3]}\")\n",
    "    if len(scores) > 4:\n",
    "        print(f\"ratio of positive/negative predictions {scores[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "GLOVE_DIR = \"./embeddings/\"\n",
    "GLOVE_FILE_NAME = \"glove.twitter.27B.\"\n",
    "GLOVE_FILE_NAME_EXT = \"d.txt\"\n",
    "\n",
    "MODEL_DIR = \"./models/blstm_models/\"\n",
    "BLSTM_BASE_FILE_NAME = \"blstm_model_\"\n",
    "BLSTM_FILE_NAME_EXT = \".h5\"\n",
    "\n",
    "N_TIMESTEPS = MAX_WORDS_PER_TWEET + 1\n",
    "NUM_EMOJI_TYPES = 20\n",
    "TEST_SPLIT_SIZE = 0.2\n",
    "VALIDATION_SPLIT = 0.1\n",
    "EARLY_STOPPING_PATIENCE = 2\n",
    "MAX_EPOCH = 30\n",
    "\n",
    "TWEET_NUM = len(text_lines)\n",
    "# TWEET_NUM = 100000\n",
    "INPUT_SIZE = int(TWEET_NUM * (1 - TEST_SPLIT_SIZE))\n",
    "NUM_OF_VOCAB = None\n",
    "EMBEDDING_SIZE = 200\n",
    "HIDDEN_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 137097\n",
      "input shape: (378767, 31)\n",
      "location labels shape: (378767, 31, 2)\n",
      "emo labels shape: (378767, 31, 21)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_input = text_lines[:TWEET_NUM]\n",
    "y_input = loc_lines[:TWEET_NUM]\n",
    "y_emo_input = emo_lines[:TWEET_NUM]\n",
    "\n",
    "abc = 100000\n",
    "\n",
    "# X_blstm_train, y_blstm_train, y_blstm_emo_train = X_input[:abc], y_input[:abc], y_emo_input[:abc]\n",
    "X_blstm_train, y_blstm_train, y_blstm_emo_train = X_input[:INPUT_SIZE], y_input[:INPUT_SIZE], y_emo_input[:INPUT_SIZE]\n",
    "X_blstm_test, y_blstm_test, y_blstm_emo_test = X_input[INPUT_SIZE:], y_input[INPUT_SIZE:], y_emo_input[INPUT_SIZE:]\n",
    "\n",
    "# X_blstm_train, X_blstm_test, y_blstm_train, y_blstm_test = train_test_split(X_input, y_input, test_size=TEST_SPLIT_SIZE)\n",
    "\n",
    "if NUM_OF_VOCAB is not None:\n",
    "    tokenizer = Tokenizer(num_words=NUM_OF_VOCAB)\n",
    "else:\n",
    "    tokenizer = Tokenizer()\n",
    "    \n",
    "tokenizer.fit_on_texts(X_input)\n",
    "word_index = tokenizer.word_index\n",
    "txt_to_seq = tokenizer.texts_to_sequences(X_blstm_train)\n",
    "# print(f\"encoded:\\n{txt_to_seq[0:5]}\\n\")\n",
    "\n",
    "if NUM_OF_VOCAB is not None:\n",
    "    vocab_size = NUM_OF_VOCAB + 1\n",
    "else:\n",
    "    vocab_size = len(word_index) + 1\n",
    "\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "\n",
    "X_blstm = pad_sequences(txt_to_seq, maxlen=N_TIMESTEPS - 1, padding='post')\n",
    "start_padding = np.zeros((X_blstm.shape[0], 1))\n",
    "X_blstm = np.append(start_padding, X_blstm, axis=1).astype(int)\n",
    "print(f\"input shape: {X_blstm.shape}\")\n",
    "# print(f\"BLSTM input example:\\n{X_blstm[:5]}\\n\")\n",
    "\n",
    "y_loc = y_blstm_train\n",
    "y_blstm = to_categorical(y_loc, num_classes=2)\n",
    "print(f\"location labels shape: {y_blstm.shape}\")\n",
    "# print(f\"\\nBLSTM loc labels:\\n{y_loc[:5]}\\n\")\n",
    "\n",
    "y_emo = y_blstm_emo_train\n",
    "y_emo_blstm = to_categorical(y_emo, num_classes=NUM_EMOJI_TYPES + 1)\n",
    "print(f\"emo labels shape: {y_emo_blstm.shape}\")\n",
    "# print(f\"\\nBLSTM emo labels:\\n{y_emo[:5]}\\n\")\n",
    "\n",
    "def calc_sample_weights(y):\n",
    "#     print(np.unique(y))\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y.flatten())\n",
    "    class_weight_dict = dict(enumerate(weights))\n",
    "#     print(f\"class weight dict:\\n{class_weight_dict}\\n\")\n",
    "    vfunc = np.vectorize(lambda x: class_weight_dict[x])\n",
    "    return vfunc(y)\n",
    "\n",
    "sample_weights_loc = calc_sample_weights(y_loc)\n",
    "# print(f\"sample_weights_loc shape: {sample_weights_loc.shape}\")\n",
    "# print(f\"sample_weights_loc examples:\\n{sample_weights_loc[:5]}\\n\")\n",
    "\n",
    "sample_weights_emo = calc_sample_weights(y_emo)\n",
    "# print(f\"sample_weights_emo shape: {sample_weights_emo.shape}\")\n",
    "# print(f\"sample_weights_emo examples:\\n{sample_weights_emo[:5]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_embedding_matrix(glove_size):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join(GLOVE_DIR, GLOVE_FILE_NAME + str(glove_size) + GLOVE_FILE_NAME_EXT), encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    embedding_matrix = np.zeros((vocab_size, glove_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= vocab_size - 1:\n",
    "            break\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i + 1] = embedding_vector\n",
    "\n",
    "    print(f\"embedding matrix shape {embedding_matrix.shape}\")\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n",
    "gloves_dict = {}\n",
    "\n",
    "def get_embedding_matrix(glove_size):\n",
    "    global gloves_dict\n",
    "    \n",
    "    if gloves_dict[glove_size] is None:\n",
    "        gloves_dict[glove_size] = load_embedding_matrix(glove_size)\n",
    "        \n",
    "    return gloves_dict[glove_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def get_param_str(embedding_size, hidden_size, n_classes, input_size):\n",
    "    param_str = \"CLA-\" + str(n_classes) + \"_INP-\" + str(input_size) + \"_EMB-\" + str(embedding_size) + \"_HID-\" + str(hidden_size)\n",
    "    return param_str\n",
    "\n",
    "def get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size):\n",
    "    param_str = get_param_str(embedding_size, hidden_size, n_classes, input_size)\n",
    "    return MODEL_DIR + BLSTM_BASE_FILE_NAME + param_str + BLSTM_FILE_NAME_EXT\n",
    "\n",
    "def save_blstm(blstm, embedding_size, hidden_size, n_classes=2, input_size=TWEET_NUM):\n",
    "    blstm.save(get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size))\n",
    "\n",
    "def load_blstm(embedding_size, hidden_size, n_classes=2, input_size=TWEET_NUM):\n",
    "    return load_model(get_blstm_file_name(embedding_size, hidden_size, n_classes, input_size))\n",
    "\n",
    "def get_callbacks():\n",
    "    callbacks = []\n",
    "    \n",
    "    callbacks.append(EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=EARLY_STOPPING_PATIENCE,\n",
    "                              verbose=0, mode='auto'))\n",
    "    checkpoint_path = MODEL_DIR + BLSTM_BASE_FILE_NAME + \"check\" + BLSTM_FILE_NAME_EXT\n",
    "    callbacks.append(ModelCheckpoint(filepath=checkpoint_path, save_best_only=True))\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def get_bi_lstm_model(embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE, n_classes=2, use_glove=True,\n",
    "                      n_timesteps=N_TIMESTEPS, mode=\"concat\"):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if use_glove:\n",
    "        embedding_matrix = get_embedding_matrix(embedding_size)\n",
    "        model.add(Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=N_TIMESTEPS,\n",
    "                            trainable=True))\n",
    "    else:\n",
    "        model.add(Embedding(vocab_size_size,\n",
    "                            embedding_size,\n",
    "                            input_length=N_TIMESTEPS))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Bidirectional(LSTM(hidden_size, return_sequences=True), merge_mode=mode))\n",
    "    model.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"], sample_weight_mode=\"temporal\")\n",
    "    return model\n",
    "\n",
    "def get_predictions(blstm, texts):\n",
    "    text_to_integer_sequences = tokenizer.texts_to_sequences(texts)\n",
    "    blstm_input = pad_sequences(text_to_integer_sequences, maxlen=N_TIMESTEPS, padding='post')\n",
    "    ypred = blstm.predict_classes(blstm_input)\n",
    "    return ypred\n",
    "\n",
    "def print_blstm_score(y_pred, y_true):\n",
    "    print_scores(calc_scores(y_pred.flatten(), y_true.flatten(), np.max(y_true)>1))\n",
    "\n",
    "def evaluate_blstm(blstm, texts=X_blstm_test, labels=y_blstm_test):\n",
    "    predictions = get_predictions(blstm, texts)\n",
    "    print(predictions.shape)\n",
    "    print(labels.shape)\n",
    "    print(predictions[:10])\n",
    "    print(labels[:10])\n",
    "    print_scores(calc_scores(predictions.flatten(), labels.flatten(), np.max(labels)>1))\n",
    "\n",
    "def do_blstm_test(embedding_size, hidden_size, is_emo=False, use_glove=True, input_size=TWEET_NUM):\n",
    "    global blstm\n",
    "    \n",
    "    if is_emo:\n",
    "        y_train = y_emo_blstm\n",
    "        y_test = y_blstm_emo_test\n",
    "        sample_weights = sample_weights_emo\n",
    "    else:\n",
    "        y_train = y_blstm\n",
    "        y_test = y_blstm_test\n",
    "        sample_weights = sample_weights_loc\n",
    "        \n",
    "    n_classes = y_train.shape[2]\n",
    "    blstm = get_bi_lstm_model(embedding_size, hidden_size, n_classes, use_glove=use_glove)\n",
    "    print(f\"\\nTraining with embedding {embedding_size} hidden {hidden_size} classes {n_classes} input {input_size} glove {use_glove}\")    \n",
    "    blstm.fit(X_blstm, y_train, epochs=MAX_EPOCH,\n",
    "              validation_split=VALIDATION_SPLIT, verbose=2,\n",
    "              sample_weight=sample_weights, callbacks=get_callbacks())\n",
    "    save_blstm(blstm, embedding_size, hidden_size, n_classes, input_size)\n",
    "    try:\n",
    "        evaluate_blstm(blstm, labels=y_test)\n",
    "    except Exception:\n",
    "        print(\"couldn't evaluate\")\n",
    "        \n",
    "def contract_intervals(y):\n",
    "    y = y.copy()\n",
    "    for i in range(y.shape[0]):\n",
    "        start = 0\n",
    "        is_interval = False\n",
    "        for j in range(y.shape[1]):\n",
    "            if y[i, j] == 1:\n",
    "                if not is_interval:\n",
    "                    start = j\n",
    "                    is_interval = True\n",
    "                y[i, j] = 0\n",
    "            else:\n",
    "                if is_interval:\n",
    "                    is_interval = False\n",
    "                    middle = int(math.ceil((start + j) / 2))\n",
    "                    y[i, middle] = 1\n",
    "    return y\n",
    "\n",
    "def get_final_predictions(blstm_loc, blstm_emo, texts):\n",
    "    loc_pred = get_predictions(blstm_loc, texts)\n",
    "    loc_pred = contract_intervals(loc_pred)\n",
    "    emo_pred = get_predictions(blstm_emo, texts)\n",
    "    final_pred = np.array([y if x > 0 else 0 for x, y in zip(loc_pred.flatten(), emo_pred.flatten())]).reshape(loc_pred.shape[0], loc_pred.shape[1])\n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "# 1  â¤\n",
    "# 2  ðŸ˜\n",
    "# 3  ðŸ˜‚\n",
    "# 4  ðŸ’•\n",
    "# 5  ðŸ”¥\n",
    "# 6  ðŸ˜Š\n",
    "# 7  ðŸ˜Ž\n",
    "# 8  âœ¨\n",
    "# 9  ðŸ’™\n",
    "# 10 ðŸ˜˜\n",
    "# 11 ðŸ“·\n",
    "# 12 ðŸ‡ºðŸ‡¸\n",
    "# 13 â˜€\n",
    "# 14 ðŸ’œ\n",
    "# 15 ðŸ˜‰\n",
    "# 16 ðŸ’¯\n",
    "# 17 ðŸ˜\n",
    "# 18 ðŸŽ„\n",
    "# 19 ðŸ“¸\n",
    "# 20 ðŸ˜œ\n",
    "\n",
    "emojis = ['\\u2764', '\\U0001f60d', '\\U0001f602', '\\U0001f495', '\\U0001f525', '\\U0001f60a', '\\U0001f60e', '\\u2728', '\\U0001f499', '\\U0001f618', '\\U0001f4f7', '\\U0001f1fa\\U0001f1f8', '\\u2600', '\\U0001f49c', '\\U0001f609', '\\U0001f4af', '\\U0001f601', '\\U0001f384', '\\U0001f4f80', '\\U0001f61c']\n",
    "\n",
    "def build_tweet(tweet, emoji_labels):\n",
    "    tweet = tweet.split()\n",
    "    result = \"\"\n",
    "    \n",
    "    for i in range(len(tweet) + 1):\n",
    "        if emoji_labels[i] > 0:\n",
    "            result += emojis[emoji_labels[i] - 1] + ' '\n",
    "        if i < len(tweet):\n",
    "            result += tweet[i] + ' '\n",
    "            \n",
    "    return result\n",
    "\n",
    "def display_tweet_results(blstm_loc, blstm_emo, tweets):\n",
    "    for tweet in tweets:\n",
    "        clean_tweet = process_tweet(tweet)\n",
    "        print(f\"\\nProcessed tweet:\\n{clean_tweet}\")\n",
    "        emoji_label_predictions = get_final_predictions(blstm_loc, blstm_emo, [clean_tweet])[0]\n",
    "        print(f\"\\nResult:\\n{build_tweet(tweet, emoji_label_predictions)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blstm_loc = load_blstm(50, 100, 2)\n",
    "blstm_emo = load_blstm(50, 100, 21)\n",
    "\n",
    "# blstm_loc = load_blstm(200, 500, 2)\n",
    "# blstm_emo = load_blstm(200, 500, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s'mores baby ! ðŸ˜ @ ocean beach , san francisco \n",
      "s'mores baby ! ðŸ’™ @ ocean beach , san francisco \n",
      "\n",
      "â¤ in the vip section somewhere @ hampton , virginia \n",
      "in the vip section ðŸ˜Ž somewhere @ hampton , virginia \n",
      "\n",
      "so much beauty in the city lights âœ¨ @user with @user @ urban lights - lacma \n",
      "so much beauty in the city lights @user with @user âœ¨ @ urban lights - lacma \n",
      "\n",
      "@user @user ily too â¤ \n",
      "@user @user ily too ðŸ˜˜ \n",
      "\n",
      "my little mini me ! love my sweet little cousin ðŸ˜Š \n",
      "my little mini me â¤ ! love my sweet little cousin â¤ \n",
      "\n",
      "carolina blue living room inspiration ! go panthers ! ðŸ’™ hope everyone enjoys the game \n",
      "carolina blue living room inspiration ! go ðŸ’™ panthers ! hope everyone enjoys the game ðŸ’™ \n",
      "\n",
      "lowkey feelin these ... ðŸ”¥ @ bloomington , minnesota \n",
      "lowkey feelin these ðŸ˜‚ ... @ bloomington , minnesota \n",
      "\n",
      "got to finally see the san diego zoo for the first time with my love ðŸ’• had so much fun on our \n",
      "got to finally see the san diego zoo for the first time with my love ðŸ˜Š had so much fun on our \n",
      "\n",
      "â¤ thiskid @ river hills golf \n",
      "thiskid â˜€ @ river hills golf \n",
      "\n",
      "even the ceiling is beautiful â¤ @ symphony hall boston \n",
      "even the ceiling is beautiful @ ðŸ˜ symphony hall boston \n",
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "num_of_tweets_to_test = 10\n",
    "\n",
    "s = slice(offset, (offset + num_of_tweets_to_test))\n",
    "y_true = y_blstm_emo_test[s]\n",
    "y_pred = get_final_predictions(blstm_loc, blstm_emo, X_blstm_test[s])\n",
    "\n",
    "# print_blstm_scores(y_pred, y_true)\n",
    "\n",
    "for i in range(num_of_tweets_to_test):\n",
    "    tweet = X_blstm_test[offset + i]\n",
    "    print(build_tweet(tweet, y_true[i]))\n",
    "    print(build_tweet(tweet, y_pred[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed tweet:\n",
      "this is the best day of my life ! i love you guys !\n",
      "\n",
      "Result:\n",
      "This is the best day of my life!!! â¤ I love you guys! \n",
      "\n",
      "\n",
      "Processed tweet:\n",
      "merry christmas everyone ! i hope you all have a nice holiday .\n",
      "\n",
      "Result:\n",
      "Merry Christmas everyone! ðŸŽ„ I hope you all have a nice holiday. \n",
      "\n",
      "\n",
      "Processed tweet:\n",
      "hahaha man you're so funny\n",
      "\n",
      "Result:\n",
      "hahaha man ðŸ˜‚ you're so funny \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from .demo.process_tweet import process_tweet\n",
    "\n",
    "tweets = [\"This is the best day of my life!!! I love you guys!\",\n",
    "         \"Merry Christmas everyone! I hope you all have a nice holiday.\",\n",
    "         \"hahaha man you're so funny\"]\n",
    "\n",
    "display_tweet_results(blstm_loc, blstm_emo, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input a tweet (text only):\n",
      "make america great again\n",
      "\n",
      "Processed tweet:\n",
      "make america great again\n",
      "\n",
      "Result:\n",
      "make america ðŸ‡ºðŸ‡¸ great again \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from .demo.process_tweet import process_tweet\n",
    "\n",
    "print(\"Please input a tweet (text only):\")\n",
    "user_input = input()\n",
    "display_tweet_results(blstm_loc, blstm_emo, [user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
