# Pool of credentials to use to crawl (each pool is specified by four properties ending with
# the same number: integer from 1 to 150)
# Credentials of the pool are used in a round robin way.
#    - for streaming crawlers it is needed to specify only one pool of credentials
#    - for rest crawler, more credential pools are specified, faster is the crawling process
# IMPORTANT: it is possible to specify up to 150 credentials

#consumerKey_1=PUT_YOUR_CONSUMER_KEY_NUM_1
#consumerSecret_1=PUT_YOUR_CONSUMER_SECRET_NUM_1
#token_1=PUT_YOUR_TOKEN_NUM_1
#tokenSecret_1=PUT_YOUR_TOKEN_SECRET_NUM_1

####################################################################################
# REST Cralwer of Twitter - by keyword(s)
# Class: org.backingdata.twitter.crawler.rest.TwitterRESTKeywordSearchCrawler
#   - Full path of the txt file to read terms from (one term ID per line)
tweetKeyword.fullPathKeywordList=./emoji_keywords.txt
#   - Full path of the output folder to store crawling results 
tweetKeyword.fullOutputDirPath=./data/
#   - Storage format: "json" to store one tweet per line as tweet JSON object or "tab" to store 
# one tweet per line as TWEET_ID<TAB>TWEET_TEXT
tweetKeyword.outputFormat=tab
#   - If not empty, it is possible specify a language to retrieve only tweet of a specific language 
# (en, es, it, etc.) - if empty all tweet are retrieved, indipendently from their language
#    IMPORTANT: The language code may be formatted as ISO 639-1 alpha-2 (en), ISO 639-3 alpha-3 (msa), or ISO 639-1 alpha-2 combined with an ISO 3166-1 alpha-2 localization (zh-tw).
tweetKeyword.languageFilter=en
